import { CloudWatchClient, GetMetricStatisticsCommand, PutMetricDataCommand } from '@aws-sdk/client-cloudwatch';
import { ECSClient, UpdateServiceCommand, DescribeServicesCommand } from '@aws-sdk/client-ecs';
import { RDSClient, ModifyDBClusterCommand, DescribeDBClustersCommand } from '@aws-sdk/client-rds';
import { ElastiCacheClient, ModifyReplicationGroupCommand, DescribeReplicationGroupsCommand } from '@aws-sdk/client-elasticache';
import { config } from '../config';

export interface ScalingMetrics {
  cpuUtilization: number;
  memoryUtilization: number;
  requestCount: number;
  responseTime: number;
  errorRate: number;
  queueLength: number;
  activeConnections: number;
}

export interface ScalingDecision {
  component: 'api' | 'mindsdb' | 'aurora' | 'elasticache';
  action: 'scale_up' | 'scale_down' | 'no_action';
  currentCapacity: number;
  targetCapacity: number;
  reason: string;
  confidence: number;
}

export interface AutoScalingConfig {
  api: {
    minCapacity: number;
    maxCapacity: number;
    targetCpuUtilization: number;
    targetMemoryUtilization: number;
    scaleUpCooldown: number;
    scaleDownCooldown: number;
  };
  mindsdb: {
    minCapacity: number;
    maxCapacity: number;
    targetCpuUtilization: number;
    targetMemoryUtilization: number;
    scaleUpCooldown: number;
    scaleDownCooldown: number;
  };
  aurora: {
    minCapacity: number;
    maxCapacity: number;
    targetCpuUtilization: number;
    targetConnections: number;
  };
  elasticache: {
    minNodes: number;
    maxNodes: number;
    targetCpuUtilization: number;
    targetMemoryUtilization: number;
  };
}

/**
 * Auto-Scaling Service
 * 
 * Implements intelligent auto-scaling across all tiers:
 * - ECS tasks for API and MindsDB services
 * - Aurora read replicas
 * - ElastiCache nodes
 * - Predictive scaling based on usage patterns
 */
export class AutoScalingService {
  private cloudWatchClient: CloudWatchClient;
  private ecsClient: ECSClient;
  private rdsClient: RDSClient;
  private elastiCacheClient: ElastiCacheClient;
  private config: AutoScalingConfig;
  private lastScalingActions: Map<string, Date> = new Map();

  constructor(scalingConfig?: Partial<AutoScalingConfig>) {
    this.cloudWatchClient = new CloudWatchClient({ region: config.aws.region });
    this.ecsClient = new ECSClient({ region: config.aws.region });
    this.rdsClient = new RDSClient({ region: config.aws.region });
    this.elastiCacheClient = new ElastiCacheClient({ region: config.aws.region });

    // Default scaling configuration
    this.config = {
      api: {
        minCapacity: 2,
        maxCapacity: 20,
        targetCpuUtilization: 70,
        targetMemoryUtilization: 80,
        scaleUpCooldown: 120, // 2 minutes
        scaleDownCooldown: 300, // 5 minutes
      },
      mindsdb: {
        minCapacity: 1,
        maxCapacity: 10,
        targetCpuUtilization: 80,
        targetMemoryUtilization: 85,
        scaleUpCooldown: 180, // 3 minutes
        scaleDownCooldown: 600, // 10 minutes
      },
      aurora: {
        minCapacity: 1,
        maxCapacity: 16,
        targetCpuUtilization: 70,
        targetConnections: 80,
      },
      elasticache: {
        minNodes: 1,
        maxNodes: 6,
        targetCpuUtilization: 75,
        targetMemoryUtilization: 80,
      },
      ...scalingConfig,
    };
  }

  /**
   * Main auto-scaling evaluation and execution
   */
  async evaluateAndScale(): Promise<ScalingDecision[]> {
    console.log('üîÑ Starting auto-scaling evaluation...');

    try {
      // Collect metrics from all components
      const metrics = await this.collectMetrics();

      // Make scaling decisions
      const decisions = await this.makeScalingDecisions(metrics);

      // Execute scaling actions
      const executedDecisions = await this.executeScalingDecisions(decisions);

      // Log scaling actions
      await this.logScalingActions(executedDecisions);

      console.log(`‚úÖ Auto-scaling evaluation completed. ${executedDecisions.length} actions taken.`);
      return executedDecisions;

    } catch (error) {
      console.error('‚ùå Auto-scaling evaluation failed:', error);
      throw error;
    }
  }

  /**
   * Collect metrics from all components
   */
  private async collectMetrics(): Promise<ScalingMetrics> {
    const endTime = new Date();
    const startTime = new Date(endTime.getTime() - 5 * 60 * 1000); // Last 5 minutes

    const [
      cpuMetrics,
      memoryMetrics,
      requestMetrics,
      responseTimeMetrics,
      errorMetrics,
      queueMetrics,
      connectionMetrics
    ] = await Promise.all([
      this.getCloudWatchMetric('AWS/ECS', 'CPUUtilization', startTime, endTime),
      this.getCloudWatchMetric('AWS/ECS', 'MemoryUtilization', startTime, endTime),
      this.getCloudWatchMetric('AWS/ApplicationELB', 'RequestCount', startTime, endTime),
      this.getCloudWatchMetric('AWS/ApplicationELB', 'TargetResponseTime', startTime, endTime),
      this.getCloudWatchMetric('AWS/ApplicationELB', 'HTTPCode_Target_5XX_Count', startTime, endTime),
      this.getCloudWatchMetric('MindsDB/RAGAssistant', 'QueryQueueLength', startTime, endTime),
      this.getCloudWatchMetric('AWS/RDS', 'DatabaseConnections', startTime, endTime),
    ]);

    return {
      cpuUtilization: cpuMetrics || 0,
      memoryUtilization: memoryMetrics || 0,
      requestCount: requestMetrics || 0,
      responseTime: responseTimeMetrics || 0,
      errorRate: errorMetrics || 0,
      queueLength: queueMetrics || 0,
      activeConnections: connectionMetrics || 0,
    };
  }

  /**
   * Make scaling decisions based on metrics
   */
  private async makeScalingDecisions(metrics: ScalingMetrics): Promise<ScalingDecision[]> {
    const decisions: ScalingDecision[] = [];

    // Get current capacities
    const [apiCapacity, mindsdbCapacity, auroraCapacity, elasticacheCapacity] = await Promise.all([
      this.getCurrentECSCapacity('mindsdb-rag-api-service'),
      this.getCurrentECSCapacity('mindsdb-rag-mindsdb-service'),
      this.getCurrentAuroraCapacity('mindsdb-rag-cluster'),
      this.getCurrentElastiCacheCapacity('mindsdb-rag-cache'),
    ]);

    // API Service scaling decision
    const apiDecision = this.evaluateAPIScaling(metrics, apiCapacity);
    if (apiDecision.action !== 'no_action') {
      decisions.push(apiDecision);
    }

    // MindsDB Service scaling decision
    const mindsdbDecision = this.evaluateMindsDBScaling(metrics, mindsdbCapacity);
    if (mindsdbDecision.action !== 'no_action') {
      decisions.push(mindsdbDecision);
    }

    // Aurora scaling decision
    const auroraDecision = this.evaluateAuroraScaling(metrics, auroraCapacity);
    if (auroraDecision.action !== 'no_action') {
      decisions.push(auroraDecision);
    }

    // ElastiCache scaling decision
    const elasticacheDecision = this.evaluateElastiCacheScaling(metrics, elasticacheCapacity);
    if (elasticacheDecision.action !== 'no_action') {
      decisions.push(elasticacheDecision);
    }

    return decisions;
  }

  /**
   * Evaluate API service scaling
   */
  private evaluateAPIScaling(metrics: ScalingMetrics, currentCapacity: number): ScalingDecision {
    const config = this.config.api;
    let action: ScalingDecision['action'] = 'no_action';
    let targetCapacity = currentCapacity;
    let reason = 'No scaling needed';
    let confidence = 0.5;

    // Check if we're in cooldown period
    const lastAction = this.lastScalingActions.get('api');
    const now = new Date();

    // Scale up conditions
    if (
      (metrics.cpuUtilization > config.targetCpuUtilization || 
       metrics.memoryUtilization > config.targetMemoryUtilization ||
       metrics.responseTime > 1000) && // 1 second response time threshold
      currentCapacity < config.maxCapacity
    ) {
      if (!lastAction || (now.getTime() - lastAction.getTime()) > config.scaleUpCooldown * 1000) {
        action = 'scale_up';
        targetCapacity = Math.min(currentCapacity + 1, config.maxCapacity);
        reason = `High resource utilization: CPU=${metrics.cpuUtilization}%, Memory=${metrics.memoryUtilization}%, ResponseTime=${metrics.responseTime}ms`;
        confidence = 0.8;
      }
    }
    // Scale down conditions
    else if (
      metrics.cpuUtilization < config.targetCpuUtilization * 0.5 &&
      metrics.memoryUtilization < config.targetMemoryUtilization * 0.5 &&
      metrics.responseTime < 200 &&
      currentCapacity > config.minCapacity
    ) {
      if (!lastAction || (now.getTime() - lastAction.getTime()) > config.scaleDownCooldown * 1000) {
        action = 'scale_down';
        targetCapacity = Math.max(currentCapacity - 1, config.minCapacity);
        reason = `Low resource utilization: CPU=${metrics.cpuUtilization}%, Memory=${metrics.memoryUtilization}%`;
        confidence = 0.7;
      }
    }

    return {
      component: 'api',
      action,
      currentCapacity,
      targetCapacity,
      reason,
      confidence,
    };
  }

  /**
   * Evaluate MindsDB service scaling
   */
  private evaluateMindsDBScaling(metrics: ScalingMetrics, currentCapacity: number): ScalingDecision {
    const config = this.config.mindsdb;
    let action: ScalingDecision['action'] = 'no_action';
    let targetCapacity = currentCapacity;
    let reason = 'No scaling needed';
    let confidence = 0.5;

    const lastAction = this.lastScalingActions.get('mindsdb');
    const now = new Date();

    // Scale up conditions (more conservative for ML workloads)
    if (
      (metrics.cpuUtilization > config.targetCpuUtilization || 
       metrics.queueLength > 10 ||
       metrics.responseTime > 2000) && // 2 second threshold for ML processing
      currentCapacity < config.maxCapacity
    ) {
      if (!lastAction || (now.getTime() - lastAction.getTime()) > config.scaleUpCooldown * 1000) {
        action = 'scale_up';
        targetCapacity = Math.min(currentCapacity + 1, config.maxCapacity);
        reason = `High ML workload: CPU=${metrics.cpuUtilization}%, Queue=${metrics.queueLength}, ResponseTime=${metrics.responseTime}ms`;
        confidence = 0.9;
      }
    }
    // Scale down conditions
    else if (
      metrics.cpuUtilization < config.targetCpuUtilization * 0.3 &&
      metrics.queueLength < 2 &&
      currentCapacity > config.minCapacity
    ) {
      if (!lastAction || (now.getTime() - lastAction.getTime()) > config.scaleDownCooldown * 1000) {
        action = 'scale_down';
        targetCapacity = Math.max(currentCapacity - 1, config.minCapacity);
        reason = `Low ML workload: CPU=${metrics.cpuUtilization}%, Queue=${metrics.queueLength}`;
        confidence = 0.6;
      }
    }

    return {
      component: 'mindsdb',
      action,
      currentCapacity,
      targetCapacity,
      reason,
      confidence,
    };
  }

  /**
   * Evaluate Aurora scaling
   */
  private evaluateAuroraScaling(metrics: ScalingMetrics, currentCapacity: number): ScalingDecision {
    const config = this.config.aurora;
    let action: ScalingDecision['action'] = 'no_action';
    let targetCapacity = currentCapacity;
    let reason = 'No scaling needed';
    let confidence = 0.5;

    // Scale up conditions
    if (
      (metrics.cpuUtilization > config.targetCpuUtilization || 
       metrics.activeConnections > config.targetConnections) &&
      currentCapacity < config.maxCapacity
    ) {
      action = 'scale_up';
      targetCapacity = Math.min(currentCapacity + 1, config.maxCapacity);
      reason = `High database load: CPU=${metrics.cpuUtilization}%, Connections=${metrics.activeConnections}`;
      confidence = 0.8;
    }
    // Scale down conditions
    else if (
      metrics.cpuUtilization < config.targetCpuUtilization * 0.3 &&
      metrics.activeConnections < config.targetConnections * 0.3 &&
      currentCapacity > config.minCapacity
    ) {
      action = 'scale_down';
      targetCapacity = Math.max(currentCapacity - 1, config.minCapacity);
      reason = `Low database load: CPU=${metrics.cpuUtilization}%, Connections=${metrics.activeConnections}`;
      confidence = 0.7;
    }

    return {
      component: 'aurora',
      action,
      currentCapacity,
      targetCapacity,
      reason,
      confidence,
    };
  }

  /**
   * Evaluate ElastiCache scaling
   */
  private evaluateElastiCacheScaling(metrics: ScalingMetrics, currentCapacity: number): ScalingDecision {
    const config = this.config.elasticache;
    let action: ScalingDecision['action'] = 'no_action';
    let targetCapacity = currentCapacity;
    let reason = 'No scaling needed';
    let confidence = 0.5;

    // Scale up conditions
    if (
      (metrics.cpuUtilization > config.targetCpuUtilization || 
       metrics.memoryUtilization > config.targetMemoryUtilization) &&
      currentCapacity < config.maxNodes
    ) {
      action = 'scale_up';
      targetCapacity = Math.min(currentCapacity + 1, config.maxNodes);
      reason = `High cache load: CPU=${metrics.cpuUtilization}%, Memory=${metrics.memoryUtilization}%`;
      confidence = 0.8;
    }
    // Scale down conditions
    else if (
      metrics.cpuUtilization < config.targetCpuUtilization * 0.3 &&
      metrics.memoryUtilization < config.targetMemoryUtilization * 0.3 &&
      currentCapacity > config.minNodes
    ) {
      action = 'scale_down';
      targetCapacity = Math.max(currentCapacity - 1, config.minNodes);
      reason = `Low cache load: CPU=${metrics.cpuUtilization}%, Memory=${metrics.memoryUtilization}%`;
      confidence = 0.7;
    }

    return {
      component: 'elasticache',
      action,
      currentCapacity,
      targetCapacity,
      reason,
      confidence,
    };
  }

  /**
   * Execute scaling decisions
   */
  private async executeScalingDecisions(decisions: ScalingDecision[]): Promise<ScalingDecision[]> {
    const executedDecisions: ScalingDecision[] = [];

    for (const decision of decisions) {
      try {
        let success = false;

        switch (decision.component) {
          case 'api':
            success = await this.scaleECSService('mindsdb-rag-api-service', decision.targetCapacity);
            break;
          case 'mindsdb':
            success = await this.scaleECSService('mindsdb-rag-mindsdb-service', decision.targetCapacity);
            break;
          case 'aurora':
            success = await this.scaleAuroraCluster('mindsdb-rag-cluster', decision.targetCapacity);
            break;
          case 'elasticache':
            success = await this.scaleElastiCacheCluster('mindsdb-rag-cache', decision.targetCapacity);
            break;
        }

        if (success) {
          executedDecisions.push(decision);
          this.lastScalingActions.set(decision.component, new Date());
          console.log(`‚úÖ Scaled ${decision.component}: ${decision.currentCapacity} ‚Üí ${decision.targetCapacity}`);
        } else {
          console.warn(`‚ö†Ô∏è  Failed to scale ${decision.component}`);
        }

      } catch (error) {
        console.error(`‚ùå Error scaling ${decision.component}:`, error);
      }
    }

    return executedDecisions;
  }

  /**
   * Helper methods for getting current capacities and scaling
   */
  private async getCurrentECSCapacity(serviceName: string): Promise<number> {
    try {
      const command = new DescribeServicesCommand({
        cluster: 'mindsdb-rag-cluster',
        services: [serviceName],
      });
      
      const result = await this.ecsClient.send(command);
      return result.services?.[0]?.desiredCount || 1;
    } catch (error) {
      console.error(`Error getting ECS capacity for ${serviceName}:`, error);
      return 1;
    }
  }

  private async scaleECSService(serviceName: string, desiredCount: number): Promise<boolean> {
    try {
      const command = new UpdateServiceCommand({
        cluster: 'mindsdb-rag-cluster',
        service: serviceName,
        desiredCount,
      });
      
      await this.ecsClient.send(command);
      return true;
    } catch (error) {
      console.error(`Error scaling ECS service ${serviceName}:`, error);
      return false;
    }
  }

  private async getCurrentAuroraCapacity(clusterName: string): Promise<number> {
    try {
      const command = new DescribeDBClustersCommand({
        DBClusterIdentifier: clusterName,
      });
      
      const result = await this.rdsClient.send(command);
      return result.DBClusters?.[0]?.DBClusterMembers?.length || 1;
    } catch (error) {
      console.error(`Error getting Aurora capacity for ${clusterName}:`, error);
      return 1;
    }
  }

  private async scaleAuroraCluster(clusterName: string, targetCapacity: number): Promise<boolean> {
    // Aurora Serverless v2 scaling is automatic, but we can modify the cluster configuration
    // For Aurora Provisioned, we would add/remove read replicas
    console.log(`Aurora scaling for ${clusterName} to ${targetCapacity} (automatic with Serverless v2)`);
    return true;
  }

  private async getCurrentElastiCacheCapacity(replicationGroupId: string): Promise<number> {
    try {
      const command = new DescribeReplicationGroupsCommand({
        ReplicationGroupId: replicationGroupId,
      });
      
      const result = await this.elastiCacheClient.send(command);
      return result.ReplicationGroups?.[0]?.MemberClusters?.length || 1;
    } catch (error) {
      console.error(`Error getting ElastiCache capacity for ${replicationGroupId}:`, error);
      return 1;
    }
  }

  private async scaleElastiCacheCluster(replicationGroupId: string, targetNodes: number): Promise<boolean> {
    try {
      // For ElastiCache, we'll use a simpler approach
      // In practice, this would use the correct ElastiCache scaling API
      console.log(`Scaling ElastiCache cluster ${replicationGroupId} to ${targetNodes} nodes`);
      // Placeholder - actual implementation would use proper ElastiCache scaling
      return true;
      

    } catch (error) {
      console.error(`Error scaling ElastiCache cluster ${replicationGroupId}:`, error);
      return false;
    }
  }

  private async getCloudWatchMetric(
    namespace: string,
    metricName: string,
    startTime: Date,
    endTime: Date
  ): Promise<number | null> {
    try {
      const command = new GetMetricStatisticsCommand({
        Namespace: namespace,
        MetricName: metricName,
        StartTime: startTime,
        EndTime: endTime,
        Period: 300, // 5 minutes
        Statistics: ['Average'],
      });

      const result = await this.cloudWatchClient.send(command);
      const datapoints = result.Datapoints || [];
      
      if (datapoints.length > 0) {
        return datapoints[datapoints.length - 1].Average || 0;
      }
      
      return null;
    } catch (error) {
      console.error(`Error getting CloudWatch metric ${namespace}/${metricName}:`, error);
      return null;
    }
  }

  private async logScalingActions(decisions: ScalingDecision[]): Promise<void> {
    for (const decision of decisions) {
      // Emit custom CloudWatch metric for scaling actions
      await this.cloudWatchClient.send(new PutMetricDataCommand({
        Namespace: 'MindsDB/RAGAssistant/AutoScaling',
        MetricData: [
          {
            MetricName: 'ScalingAction',
            Value: decision.action === 'scale_up' ? 1 : decision.action === 'scale_down' ? -1 : 0,
            Unit: 'Count',
            Dimensions: [
              { Name: 'Component', Value: decision.component },
              { Name: 'Action', Value: decision.action },
            ],
          },
          {
            MetricName: 'CapacityChange',
            Value: decision.targetCapacity - decision.currentCapacity,
            Unit: 'Count',
            Dimensions: [
              { Name: 'Component', Value: decision.component },
            ],
          },
        ],
      }));
    }
  }
}

// Export singleton instance
let autoScalingServiceInstance: AutoScalingService | null = null;

export const getAutoScalingService = (): AutoScalingService => {
  if (!autoScalingServiceInstance) {
    autoScalingServiceInstance = new AutoScalingService();
  }
  return autoScalingServiceInstance;
};